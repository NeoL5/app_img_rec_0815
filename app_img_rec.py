# -*- coding: utf-8 -*-
# @Author  : Zhiyi Leung
# @Time    : 2024/8/13 16:09
import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode
import av
import cv2
import numpy as np


ANGLE_THRESHOLD = 10  # è§’åº¦é˜ˆå€¼ï¼Œæ»¤é™¤æ¥è¿‘æ°´å¹³çš„çº¿æ¡

st.title("Real-time object detectionğŸ˜")
st.subheader("This app allow you to play with image filters")
# ä¾§è¾¹æ æ»‘åŠ¨æ¡
blur_rate = st.sidebar.slider("Blurring", min_value=0.5, max_value=3.5)
# ä¾§è¾¹æ å¤é€‰æ¡†
apply_enhancement_filter = st.sidebar.checkbox('Enhance Details')


# é«˜æ–¯æ¨¡ç³Š
def blur_image(image, amount):
    blur_img = cv2.GaussianBlur(image, (11, 11), amount)
    return blur_img


# ç»†èŠ‚å¢å¼º
def enhance_details(img):
    hdr = cv2.detailEnhance(img, sigma_s=12, sigma_r=0.15)
    return hdr


def video_frame_callback(frame):
    # å°†frameè½¬æ¢ä¸ºNumPyæ•°ç»„imgï¼Œè½¬æ¢ååŒ…å«(height, width, 3)
    img = frame.to_ndarray(format="bgr24")

    processed_image = blur_image(img, blur_rate)

    if apply_enhancement_filter:
        processed_image = enhance_details(processed_image)

    # è½¬æ¢ä¸ºç°åº¦å›¾åƒ
    gray_image = cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
    # è¿›è¡Œè¾¹ç¼˜æ£€æµ‹
    edges = cv2.Canny(gray_image, 50, 150)
    # ä½¿ç”¨éœå¤«å˜æ¢æ£€æµ‹çº¿æ¡
    lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi / 180, threshold=80, minLineLength=50, maxLineGap=10)

    # æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°çº¿æ¡
    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line[0]

            # è®¡ç®—çº¿æ¡çš„è§’åº¦
            angle = np.arctan2(y2 - y1, x2 - x1) * 180.0 / np.pi

            # è½¬æ¢ä¸ºç›¸å¯¹äºæ°´å¹³é¢çš„è§’åº¦
            if angle < 0:
                angle += 180
            if angle > 90:
                angle = 180 - angle

            # è¿‡æ»¤æ‰æ¥è¿‘æ°´å¹³çš„çº¿æ¡
            if angle < ANGLE_THRESHOLD:
                continue

            # ç»˜åˆ¶æ£€æµ‹åˆ°çš„çº¿æ¡
            cv2.line(img, (x1, y1), (x2, y2), (255, 255, 0), 2)

            # å°†è§’åº¦æ ‡æ³¨åœ¨å›¾åƒä¸Š
            mid_x, mid_y = (x1 + x2) // 2, (y1 + y2) // 2  # è®¡ç®—çº¿æ®µçš„ä¸­ç‚¹
            text = f'{angle:.1f}'
            cv2.putText(img, text, (mid_x, mid_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv2.LINE_AA)

    return av.VideoFrame.from_ndarray(img, format="bgr24")  # é‡è®¾ä¸ºBRG24æ ¼å¼


def main_loop():
    # æŒ‡å®šå›è°ƒå‡½æ•°ï¼Œè§†é¢‘æµä¸­çš„æ¯ä¸€å¸§è¢«æ•è·æ—¶è°ƒç”¨ã€‚
    webrtc_streamer(key="object-detection",
                    mode=WebRtcMode.SENDRECV,
                    video_frame_callback=video_frame_callback,
                    media_stream_constraints={"video": True, "audio": False},
                    async_processing=True)


if __name__ == '__main__':
    main_loop()
